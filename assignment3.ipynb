{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aad3a532",
   "metadata": {},
   "source": [
    "1. Using the titanic data gotten from kaggle, and with your current knowledge of any of the classification models you are familiar with, perform a classification algorithm to determine passengers that are most likely to survive the titanic crash\n",
    "Link to Data: Titanic dataset (kaggle.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cba0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "df = pd.read_csv('titanic.csv')\n",
    "# print(f'\\ninitial header: {df.columns.tolist()}')\n",
    "df.insert(0, 'passengerId', range(1, len(df) + 1))\n",
    "# print(f'new header: {df.columns.tolist()}')\n",
    "# print(df.dtypes)\n",
    "# print(df.head())\n",
    "\n",
    "\n",
    "cols_keep = [\"passengerId\",\"sex\",\"age\",\"sibsp\",\"parch\",\"fare\",\"embarked\",\"survived\",\"class\"]\n",
    "df = df[cols_keep]\n",
    "# print(df.columns)\n",
    "\n",
    "# Preprocessing setup\n",
    "numeric_features = [\"age\",\"sibsp\",\"parch\",\"fare\"]\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_features = [\"sex\",\"embarked\"]\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"cat\", categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# Prepare X, y\n",
    "X = df.drop(columns=[\"passengerId\",\"survived\"])\n",
    "y = df[\"survived\"]\n",
    "\n",
    "x_pre = preprocessor.fit_transform(X)\n",
    "\n",
    "cat_names = preprocessor.named_transformers_[\"cat\"][\"onehot\"].get_feature_names_out(categorical_features)\n",
    "feature_names = numeric_features + list(cat_names)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_pre, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Models\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "\n",
    "lr.fit(x_train, y_train)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "y_pred_lr = lr.predict(x_test)\n",
    "y_proba_lr = lr.predict_proba(x_test)[:, 1]\n",
    "y_pred_rf = rf.predict(x_test)\n",
    "y_proba_rf = rf.predict_proba(x_test)[:, 1]\n",
    "\n",
    "def eval_model(name, y_true, y_pred, y_proba=None):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_proba)\n",
    "    print(f\"{name} Accuracy: {acc:.4f}\")\n",
    "    print(f\"{name} ROC AUC: {roc_auc:.4f}\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    if y_proba is not None:\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
    "        # plt.figure()\n",
    "        # plt.plot(fpr, tpr, label=f'{name} (area = {roc_auc:.2f})')\n",
    "        # plt.plot([0, 1], [0, 1], 'k--')\n",
    "        # plt.xlabel('False Positive Rate')\n",
    "        # plt.ylabel('True Positive Rate')\n",
    "        # plt.title(f'ROC Curve - {name}')\n",
    "        # plt.legend(loc='lower right')\n",
    "        # plt.show()\n",
    "\n",
    "eval_model(\"Logistic Regression\", y_test, y_pred_lr, y_proba_lr)\n",
    "eval_model(\"Random Forest\", y_test, y_pred_rf, y_proba_rf)\n",
    "\n",
    "print(\"\\nCross-val (5-fold) accuracy:\")\n",
    "print(\"LogReg:\", cross_val_score(lr, x_pre, y, cv=5, scoring=\"accuracy\").mean().round(4))\n",
    "print(\"RandomForest:\", cross_val_score(rf, x_pre, y, cv=5, scoring=\"accuracy\").mean().round(4))\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "feat_imp = pd.DataFrame({'Feature': feature_names, 'Importance': importances}).sort_values('Importance', ascending=False)\n",
    "# plt.figure(figsize=(10,6))\n",
    "# plt.barh(feat_imp['Feature'], feat_imp['Importance'])\n",
    "# plt.xlabel('Importance')\n",
    "# plt.title('Feature Importances from Random Forest')\n",
    "# plt.show()\n",
    "\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_proba_lr)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_proba_rf)\n",
    "# plt.figure()\n",
    "# plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (area = {roc_auc_score(y_test, y_proba_lr):.2f})')\n",
    "# plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (area = {roc_auc_score(y_test, y_proba_rf):.2f})')\n",
    "# plt.plot([0, 1], [0, 1], 'k--')\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('ROC Curve Comparison')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.show()\n",
    "\n",
    "x_full_pre = preprocessor.transform(df.drop(columns=[\"passengerId\",\"survived\"]))\n",
    "proba_all_rf = rf.predict_proba(x_full_pre)[:, 1]\n",
    "output = pd.DataFrame({'passengerId': df['passengerId'], 'survived_Prob_RF': proba_all_rf})\n",
    "output = pd.merge(df, output, on='passengerId')\n",
    "output.to_csv('results.csv', index=False)\n",
    "# output.to_csv('titanic_survival_probabilities.csv', index=False)\n",
    "\n",
    "print(\"\\nPredictions saved to 'results.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a255bd",
   "metadata": {},
   "source": [
    "2. Using the dataset provided, build a model to classify emails as spam or not spam.\n",
    "Link to Data:  Spam Mails Dataset (kaggle.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9f7f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Step 2: Load dataset\n",
    "df = pd.read_csv(\"spam_ham_dataset.csv\")   # adjust filename if different\n",
    "print(df.head())\n",
    "df['text'] = df['text'].astype(str)  # Ensure text column is string\n",
    "# print(df['Category'].value_counts())\n",
    "\n",
    "# Dataset typically has \"Category\" (ham/spam) and \"Message\"\n",
    "# Rename for convenience\n",
    "df = df.rename(columns={\"Category\": \"label\", \"Message\": \"text\"})\n",
    "\n",
    "# Encode labels: ham=0, spam=1\n",
    "df['label'] = df['label'].map({\"ham\": 0, \"spam\": 1})\n",
    "\n",
    "# Step 3: Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'], df['label'], test_size=0.2, random_state=42, stratify=df['label']\n",
    ")\n",
    "\n",
    "# Step 4: Build pipelines\n",
    "\n",
    "# Logistic Regression with TF-IDF\n",
    "lr_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('clf', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "nb_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "xgb_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('clf', XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42))\n",
    "])\n",
    "\n",
    "lgbm_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('clf', LGBMClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Naive Bayes with TF-IDF\n",
    "nb_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Step 5: Train models\n",
    "lr_clf.fit(X_train, y_train)\n",
    "nb_clf.fit(X_train, y_train)\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "lgbm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Predictions\n",
    "def model_predictions(model, X_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    return y_pred, y_proba\n",
    "y_pred_lr, y_proba_lr = model_predictions(lr_clf, X_test)\n",
    "y_pred_nb, y_proba_nb = model_predictions(nb_clf, X_test)\n",
    "y_pred_xgb, y_proba_xgb = model_predictions(xgb_clf, X_test)\n",
    "y_pred_lgbm, y_proba_lgbm = model_predictions(lgbm_clf, X_test)\n",
    "\n",
    "# y_pred_lr = lr_clf.predict(X_test)\n",
    "# y_proba_lr = lr_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# y_pred_nb = nb_clf.predict(X_test)\n",
    "# y_proba_nb = nb_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Step 7: Evaluation function\n",
    "def eval_model(name, y_true, y_pred, y_proba):\n",
    "    print(f\"\\n{name} Results\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"ROC AUC:\", roc_auc_score(y_true, y_proba))\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC={roc_auc_score(y_true, y_proba):.2f})')\n",
    "\n",
    "# Step 8: Evaluate both models\n",
    "eval_model(\"Logistic Regression\", y_test, y_pred_lr, y_proba_lr)\n",
    "eval_model(\"Naive Bayes\", y_test, y_pred_nb, y_proba_nb)\n",
    "eval_model(\"XGBoost\", y_test, y_pred_xgb, y_proba_xgb)\n",
    "eval_model(\"LightGBM\", y_test, y_pred_lgbm, y_proba_lgbm)\n",
    "\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - Spam Classification\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Step 9: Cross-validation (for robustness)\n",
    "print(\"\\nCross-validation scores:\")\n",
    "print(\"Logistic Regression:\", cross_val_score(lr_clf, df['text'], df['label'], cv=5).mean().round(4))\n",
    "print(\"Naive Bayes:\", cross_val_score(nb_clf, df['text'], df['label'], cv=5).mean().round(4))\n",
    "\n",
    "\n",
    "# Example emails to test\n",
    "test_emails = [\n",
    "    \"Congratulations! You've won a $1,000 Walmart gift card. Click here to claim your prize.\",\n",
    "    \"Hi John, are we still on for the meeting tomorrow?\",\n",
    "    \"URGENT! Your account has been compromised. Please reset your password immediately.\",\n",
    "    \"Hey, just checking in to see how you're doing.\",\n",
    "    \"hi bro, do you still care for the loan?\",\n",
    "    \"You have a new voicemail. Call now to listen to your messages.\"\n",
    "]\n",
    "\n",
    "# Predict with Logistic Regression model\n",
    "threshold = 0.6\n",
    "probs = lr_clf.predict_proba(test_emails)[:, 1]  # probability of spam\n",
    "probs_nb = nb_clf.predict_proba(test_emails)[:, 1]\n",
    "probs_xgb = xgb_clf.predict_proba(test_emails)[:, 1]\n",
    "probs_lgbm = lgbm_clf.predict_proba(test_emails)[:, 1]\n",
    "# preds = lr_clf.predict(test_emails)\n",
    "preds = (probs >= threshold).astype(int)  # apply threshold\n",
    "preds_nb = (probs_nb >= threshold).astype(int)\n",
    "preds_xgb = (probs_xgb >= threshold).astype(int)\n",
    "preds_lgbm = (probs_lgbm >= threshold).astype(int)\n",
    "\n",
    "def is_spam(model_name,test_emails, preds, probs):\n",
    "    print(f'model name: {model_name}:')\n",
    "    for email, label, prob in zip(test_emails, preds, probs):\n",
    "        print(f\"Email: {email}\")\n",
    "        print(f\"Predicted: {'SPAM' if label == 1 else 'NOT SPAM'} (probability {prob:.2f})\")\n",
    "    print(\"...............................................................\\n\")\n",
    "is_spam(\"logistic regression\",test_emails, preds, probs)\n",
    "is_spam(\"naive bayes\",test_emails, preds_nb, probs_nb)\n",
    "is_spam(\"LightGBM\",test_emails, preds_lgbm, probs_lgbm)\n",
    "is_spam(\"XGBoost\",test_emails, preds_xgb, probs_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0d753e",
   "metadata": {},
   "source": [
    "using fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4058ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'label', 'text', 'label_num'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='105070592' class='' max='105067061' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [105070592/105067061 00:47&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='33' class='' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [33/33 01:43&lt;00:00 0.3616]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Exception occured in `Recorder` when calling event `after_validate`:\n\ty should be a 1d array, got an array of shape (1034, 2) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Build a text classifier using AWD_LSTM\u001b[39;00m\n\u001b[32m     31\u001b[39m learn = text_classifier_learner(dls, AWD_LSTM, drop_mult=\u001b[32m0.5\u001b[39m, metrics=[accuracy, RocAuc()])\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m learn.fine_tune(\u001b[32m4\u001b[39m)  \u001b[38;5;66;03m# you can increase epochs if needed\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# test emails to make predictions on\u001b[39;00m\n\u001b[32m     35\u001b[39m test_emails = [\n\u001b[32m     36\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mCongratulations! You\u001b[39m\u001b[33m'\u001b[39m\u001b[33mve won a $1,000 Walmart gift card. Click here to claim your prize.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     37\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mHi John, are we still on for the meeting tomorrow?\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     41\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mYou have a new voicemail. Call now to listen to your messages.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     42\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pyint_env/lib/python3.13/site-packages/fastai/callback/schedule.py:167\u001b[39m, in \u001b[36mfine_tune\u001b[39m\u001b[34m(self, epochs, base_lr, freeze_epochs, lr_mult, pct_start, div, **kwargs)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[33m\"\u001b[39m\u001b[33mFine tune with `Learner.freeze` for `freeze_epochs`, then with `Learner.unfreeze` for `epochs`, using discriminative LR.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    166\u001b[39m \u001b[38;5;28mself\u001b[39m.freeze()\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m \u001b[38;5;28mself\u001b[39m.fit_one_cycle(freeze_epochs, \u001b[38;5;28mslice\u001b[39m(base_lr), pct_start=\u001b[32m0.99\u001b[39m, **kwargs)\n\u001b[32m    168\u001b[39m base_lr /= \u001b[32m2\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28mself\u001b[39m.unfreeze()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pyint_env/lib/python3.13/site-packages/fastai/callback/schedule.py:121\u001b[39m, in \u001b[36mfit_one_cycle\u001b[39m\u001b[34m(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt, start_epoch)\u001b[39m\n\u001b[32m    118\u001b[39m lr_max = np.array([h[\u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.opt.hypers])\n\u001b[32m    119\u001b[39m scheds = {\u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m: combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final),\n\u001b[32m    120\u001b[39m           \u001b[33m'\u001b[39m\u001b[33mmom\u001b[39m\u001b[33m'\u001b[39m: combined_cos(pct_start, *(\u001b[38;5;28mself\u001b[39m.moms \u001b[38;5;28;01mif\u001b[39;00m moms \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m moms))}\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28mself\u001b[39m.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd, start_epoch=start_epoch)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pyint_env/lib/python3.13/site-packages/fastai/learner.py:272\u001b[39m, in \u001b[36mLearner.fit\u001b[39m\u001b[34m(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\u001b[39m\n\u001b[32m    270\u001b[39m \u001b[38;5;28mself\u001b[39m.opt.set_hypers(lr=\u001b[38;5;28mself\u001b[39m.lr \u001b[38;5;28;01mif\u001b[39;00m lr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m lr)\n\u001b[32m    271\u001b[39m \u001b[38;5;28mself\u001b[39m.n_epoch = n_epoch\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m \u001b[38;5;28mself\u001b[39m._with_events(\u001b[38;5;28mself\u001b[39m._do_fit, \u001b[33m'\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m'\u001b[39m, CancelFitException, \u001b[38;5;28mself\u001b[39m._end_cleanup)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pyint_env/lib/python3.13/site-packages/fastai/learner.py:207\u001b[39m, in \u001b[36mLearner._with_events\u001b[39m\u001b[34m(self, f, event_type, ex, final)\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final=noop):\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m);  f()\n\u001b[32m    208\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m    209\u001b[39m     \u001b[38;5;28mself\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m);  final()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pyint_env/lib/python3.13/site-packages/fastai/learner.py:261\u001b[39m, in \u001b[36mLearner._do_fit\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.n_epoch):\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.epoch=epoch\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m     \u001b[38;5;28mself\u001b[39m._with_events(\u001b[38;5;28mself\u001b[39m._do_epoch, \u001b[33m'\u001b[39m\u001b[33mepoch\u001b[39m\u001b[33m'\u001b[39m, CancelEpochException)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pyint_env/lib/python3.13/site-packages/fastai/learner.py:207\u001b[39m, in \u001b[36mLearner._with_events\u001b[39m\u001b[34m(self, f, event_type, ex, final)\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final=noop):\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m);  f()\n\u001b[32m    208\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m    209\u001b[39m     \u001b[38;5;28mself\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m);  final()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pyint_env/lib/python3.13/site-packages/fastai/learner.py:256\u001b[39m, in \u001b[36mLearner._do_epoch\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_do_epoch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._do_epoch_train()\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28mself\u001b[39m._do_epoch_validate()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pyint_env/lib/python3.13/site-packages/fastai/learner.py:252\u001b[39m, in \u001b[36mLearner._do_epoch_validate\u001b[39m\u001b[34m(self, ds_idx, dl)\u001b[39m\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: dl = \u001b[38;5;28mself\u001b[39m.dls[ds_idx]\n\u001b[32m    251\u001b[39m \u001b[38;5;28mself\u001b[39m.dl = dl\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad(): \u001b[38;5;28mself\u001b[39m._with_events(\u001b[38;5;28mself\u001b[39m.all_batches, \u001b[33m'\u001b[39m\u001b[33mvalidate\u001b[39m\u001b[33m'\u001b[39m, CancelValidException)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pyint_env/lib/python3.13/site-packages/fastai/learner.py:209\u001b[39m, in \u001b[36mLearner._with_events\u001b[39m\u001b[34m(self, f, event_type, ex, final)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m);  f()\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m);  final()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pyint_env/lib/python3.13/site-packages/fastai/learner.py:180\u001b[39m, in \u001b[36mLearner.__call__\u001b[39m\u001b[34m(self, event_name)\u001b[39m\n\u001b[32m    177\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m: \u001b[38;5;28mself\u001b[39m.add_cbs(cbs)\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mordered_cbs\u001b[39m(\u001b[38;5;28mself\u001b[39m, event): \u001b[38;5;28;01mreturn\u001b[39;00m [cb \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cbs.sorted(\u001b[33m'\u001b[39m\u001b[33morder\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(cb, event)]\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, event_name): L(event_name).map(\u001b[38;5;28mself\u001b[39m._call_one)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call_one\u001b[39m(\u001b[38;5;28mself\u001b[39m, event_name):\n\u001b[32m    183\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(event, event_name): \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mmissing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pyint_env/lib/python3.13/site-packages/fastcore/foundation.py:163\u001b[39m, in \u001b[36mL.map\u001b[39m\u001b[34m(self, f, *args, **kwargs)\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, *args, **kwargs): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._new(map_ex(\u001b[38;5;28mself\u001b[39m, f, *args, gen=\u001b[38;5;28;01mFalse\u001b[39;00m, **kwargs))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pyint_env/lib/python3.13/site-packages/fastcore/basics.py:934\u001b[39m, in \u001b[36mmap_ex\u001b[39m\u001b[34m(iterable, f, gen, *args, **kwargs)\u001b[39m\n\u001b[32m    932\u001b[39m res = \u001b[38;5;28mmap\u001b[39m(g, iterable)\n\u001b[32m    933\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m gen: \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[32m--> \u001b[39m\u001b[32m934\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pyint_env/lib/python3.13/site-packages/fastcore/basics.py:919\u001b[39m, in \u001b[36mbind.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    917\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v,_Arg): kwargs[k] = args.pop(v.i)\n\u001b[32m    918\u001b[39m fargs = [args[x.i] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, _Arg) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pargs] + args[\u001b[38;5;28mself\u001b[39m.maxi+\u001b[32m1\u001b[39m:]\n\u001b[32m--> \u001b[39m\u001b[32m919\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.func(*fargs, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pyint_env/lib/python3.13/site-packages/fastai/learner.py:184\u001b[39m, in \u001b[36mLearner._call_one\u001b[39m\u001b[34m(self, event_name)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call_one\u001b[39m(\u001b[38;5;28mself\u001b[39m, event_name):\n\u001b[32m    183\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(event, event_name): \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mmissing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cbs.sorted(\u001b[33m'\u001b[39m\u001b[33morder\u001b[39m\u001b[33m'\u001b[39m): cb(event_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pyint_env/lib/python3.13/site-packages/fastai/callback/core.py:64\u001b[39m, in \u001b[36mCallback.__call__\u001b[39m\u001b[34m(self, event_name)\u001b[39m\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m: res = getcallable(\u001b[38;5;28mself\u001b[39m, event_name)()\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (CancelBatchException, CancelBackwardException, CancelEpochException, CancelFitException, CancelStepException, CancelTrainException, CancelValidException): \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e: \u001b[38;5;28;01mraise\u001b[39;00m modify_exception(e, \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mException occured in `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` when calling event `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me.args[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m, replace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event_name==\u001b[33m'\u001b[39m\u001b[33mafter_fit\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mself\u001b[39m.run=\u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;66;03m#Reset self.run to True at each end of fit\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pyint_env/lib/python3.13/site-packages/fastai/callback/core.py:62\u001b[39m, in \u001b[36mCallback.__call__\u001b[39m\u001b[34m(self, event_name)\u001b[39m\n\u001b[32m     60\u001b[39m res = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.run \u001b[38;5;129;01mand\u001b[39;00m _run: \n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m: res = getcallable(\u001b[38;5;28mself\u001b[39m, event_name)()\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (CancelBatchException, CancelBackwardException, CancelEpochException, CancelFitException, CancelStepException, CancelTrainException, CancelValidException): \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e: \u001b[38;5;28;01mraise\u001b[39;00m modify_exception(e, \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mException occured in `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` when calling event `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me.args[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m, replace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pyint_env/lib/python3.13/site-packages/fastai/learner.py:589\u001b[39m, in \u001b[36mRecorder.after_validate\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    587\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbefore_validate\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;28mself\u001b[39m._valid_mets.map(Self.reset())\n\u001b[32m    588\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mafter_train\u001b[39m   (\u001b[38;5;28mself\u001b[39m): \u001b[38;5;28mself\u001b[39m.log += \u001b[38;5;28mself\u001b[39m._train_mets.map(_maybe_item)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mafter_validate\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;28mself\u001b[39m.log += \u001b[38;5;28mself\u001b[39m._valid_mets.map(_maybe_item)\n\u001b[32m    590\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mafter_cancel_train\u001b[39m(\u001b[38;5;28mself\u001b[39m):    \u001b[38;5;28mself\u001b[39m.cancel_train = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mafter_cancel_validate\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;28mself\u001b[39m.cancel_valid = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pyint_env/lib/python3.13/site-packages/fastcore/foundation.py:163\u001b[39m, in \u001b[36mL.map\u001b[39m\u001b[34m(self, f, *args, **kwargs)\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, *args, **kwargs): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._new(map_ex(\u001b[38;5;28mself\u001b[39m, f, *args, gen=\u001b[38;5;28;01mFalse\u001b[39;00m, **kwargs))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pyint_env/lib/python3.13/site-packages/fastcore/basics.py:934\u001b[39m, in \u001b[36mmap_ex\u001b[39m\u001b[34m(iterable, f, gen, *args, **kwargs)\u001b[39m\n\u001b[32m    932\u001b[39m res = \u001b[38;5;28mmap\u001b[39m(g, iterable)\n\u001b[32m    933\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m gen: \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[32m--> \u001b[39m\u001b[32m934\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pyint_env/lib/python3.13/site-packages/fastcore/basics.py:919\u001b[39m, in \u001b[36mbind.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    917\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v,_Arg): kwargs[k] = args.pop(v.i)\n\u001b[32m    918\u001b[39m fargs = [args[x.i] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, _Arg) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pargs] + args[\u001b[38;5;28mself\u001b[39m.maxi+\u001b[32m1\u001b[39m:]\n\u001b[32m--> \u001b[39m\u001b[32m919\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.func(*fargs, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pyint_env/lib/python3.13/site-packages/fastai/learner.py:543\u001b[39m, in \u001b[36m_maybe_item\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m    542\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_item\u001b[39m(t):\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m     t = t.value\n\u001b[32m    544\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m t.item()\n\u001b[32m    545\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pyint_env/lib/python3.13/site-packages/fastai/metrics.py:73\u001b[39m, in \u001b[36mAccumMetric.value\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     71\u001b[39m preds,targs = torch.cat(\u001b[38;5;28mself\u001b[39m.preds),torch.cat(\u001b[38;5;28mself\u001b[39m.targs)\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_np: preds,targs = preds.numpy(),targs.numpy()\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.func(targs, preds, **\u001b[38;5;28mself\u001b[39m.kwargs) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.invert_args \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.func(preds, targs, **\u001b[38;5;28mself\u001b[39m.kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pyint_env/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pyint_env/lib/python3.13/site-packages/sklearn/metrics/_ranking.py:686\u001b[39m, in \u001b[36mroc_auc_score\u001b[39m\u001b[34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[39m\n\u001b[32m    684\u001b[39m     labels = np.unique(y_true)\n\u001b[32m    685\u001b[39m     y_true = label_binarize(y_true, classes=labels)[:, \u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m686\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[32m    687\u001b[39m         partial(_binary_roc_auc_score, max_fpr=max_fpr),\n\u001b[32m    688\u001b[39m         y_true,\n\u001b[32m    689\u001b[39m         y_score,\n\u001b[32m    690\u001b[39m         average,\n\u001b[32m    691\u001b[39m         sample_weight=sample_weight,\n\u001b[32m    692\u001b[39m     )\n\u001b[32m    693\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# multilabel-indicator\u001b[39;00m\n\u001b[32m    694\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[32m    695\u001b[39m         partial(_binary_roc_auc_score, max_fpr=max_fpr),\n\u001b[32m    696\u001b[39m         y_true,\n\u001b[32m   (...)\u001b[39m\u001b[32m    699\u001b[39m         sample_weight=sample_weight,\n\u001b[32m    700\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pyint_env/lib/python3.13/site-packages/sklearn/metrics/_base.py:69\u001b[39m, in \u001b[36m_average_binary_score\u001b[39m\u001b[34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[39m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m format is not supported\u001b[39m\u001b[33m\"\u001b[39m.format(y_type))\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y_type == \u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m binary_metric(y_true, y_score, sample_weight=sample_weight)\n\u001b[32m     71\u001b[39m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[32m     72\u001b[39m y_true = check_array(y_true)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pyint_env/lib/python3.13/site-packages/sklearn/metrics/_ranking.py:433\u001b[39m, in \u001b[36m_binary_roc_auc_score\u001b[39m\u001b[34m(y_true, y_score, sample_weight, max_fpr)\u001b[39m\n\u001b[32m    424\u001b[39m     warnings.warn(\n\u001b[32m    425\u001b[39m         (\n\u001b[32m    426\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOnly one class is present in y_true. ROC AUC score \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    429\u001b[39m         UndefinedMetricWarning,\n\u001b[32m    430\u001b[39m     )\n\u001b[32m    431\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.nan\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m fpr, tpr, _ = roc_curve(y_true, y_score, sample_weight=sample_weight)\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m max_fpr == \u001b[32m1\u001b[39m:\n\u001b[32m    435\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m auc(fpr, tpr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pyint_env/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:191\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n\u001b[32m    193\u001b[39m func_sig = signature(func)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pyint_env/lib/python3.13/site-packages/sklearn/metrics/_ranking.py:1163\u001b[39m, in \u001b[36mroc_curve\u001b[39m\u001b[34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[39m\n\u001b[32m   1059\u001b[39m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[32m   1060\u001b[39m     {\n\u001b[32m   1061\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33my_true\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33marray-like\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1070\u001b[39m     y_true, y_score, *, pos_label=\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1071\u001b[39m ):\n\u001b[32m   1072\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[32m   1073\u001b[39m \n\u001b[32m   1074\u001b[39m \u001b[33;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1161\u001b[39m \u001b[33;03m    array([ inf, 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[32m   1162\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1163\u001b[39m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[32m   1164\u001b[39m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight\n\u001b[32m   1165\u001b[39m     )\n\u001b[32m   1167\u001b[39m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[32m   1168\u001b[39m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[32m   1169\u001b[39m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1174\u001b[39m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[32m   1175\u001b[39m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[32m   1176\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) > \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pyint_env/lib/python3.13/site-packages/sklearn/metrics/_ranking.py:867\u001b[39m, in \u001b[36m_binary_clf_curve\u001b[39m\u001b[34m(y_true, y_score, pos_label, sample_weight)\u001b[39m\n\u001b[32m    865\u001b[39m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[32m    866\u001b[39m y_true = column_or_1d(y_true)\n\u001b[32m--> \u001b[39m\u001b[32m867\u001b[39m y_score = column_or_1d(y_score)\n\u001b[32m    868\u001b[39m assert_all_finite(y_true)\n\u001b[32m    869\u001b[39m assert_all_finite(y_score)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pyint_env/lib/python3.13/site-packages/sklearn/utils/validation.py:1483\u001b[39m, in \u001b[36mcolumn_or_1d\u001b[39m\u001b[34m(y, dtype, warn, device)\u001b[39m\n\u001b[32m   1470\u001b[39m         warnings.warn(\n\u001b[32m   1471\u001b[39m             (\n\u001b[32m   1472\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mA column-vector y was passed when a 1d array was\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1477\u001b[39m             stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m   1478\u001b[39m         )\n\u001b[32m   1479\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _asarray_with_order(\n\u001b[32m   1480\u001b[39m         xp.reshape(y, (-\u001b[32m1\u001b[39m,)), order=\u001b[33m\"\u001b[39m\u001b[33mC\u001b[39m\u001b[33m\"\u001b[39m, xp=xp, device=device\n\u001b[32m   1481\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1483\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1484\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33my should be a 1d array, got an array of shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m instead.\u001b[39m\u001b[33m\"\u001b[39m.format(shape)\n\u001b[32m   1485\u001b[39m )\n",
      "\u001b[31mValueError\u001b[39m: Exception occured in `Recorder` when calling event `after_validate`:\n\ty should be a 1d array, got an array of shape (1034, 2) instead."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from fastai.text.all import *\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"spam_ham_dataset.csv\")\n",
    "print(df.columns)\n",
    "df = df.rename(columns={\"Category\": \"label\", \"Message\": \"text\"})\n",
    "# Encode labels: ham=0, spam=1\n",
    "df['label'] = df['label'].map({\"ham\": 0, \"spam\": 1})\n",
    "\n",
    "\n",
    "splits = RandomSplitter(seed=42)(range_of(df))\n",
    "\n",
    "# Create DataBlock\n",
    "# dblock = DataBlock(\n",
    "#     blocks=(TextBlock.from_df('text', is_lm=False), CategoryBlock),\n",
    "#     get_y=ColReader('label'),\n",
    "#     splitter=IndexSplitter(splits[1])\n",
    "# )\n",
    "# Create DataBlock with proper splitter\n",
    "dblock = DataBlock(\n",
    "    blocks=(TextBlock.from_df('text', is_lm=False), CategoryBlock),\n",
    "    get_x=ColReader('text'),\n",
    "    get_y=ColReader('label'),\n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=42)\n",
    ")\n",
    "\n",
    "dls = dblock.dataloaders(df, bs=32)\n",
    "\n",
    "# Build a text classifier using AWD_LSTM\n",
    "learn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=[accuracy, RocAuc()])\n",
    "learn.fine_tune(4)  # you can increase epochs if needed\n",
    "\n",
    "# test emails to make predictions on\n",
    "test_emails = [\n",
    "    \"Congratulations! You've won a $1,000 Walmart gift card. Click here to claim your prize.\",\n",
    "    \"Hi John, are we still on for the meeting tomorrow?\",\n",
    "    \"URGENT! Your account has been compromised. Please reset your password immediately.\",\n",
    "    \"Hey, just checking in to see how you're doing.\",\n",
    "    \"hi bro, do you still care for the loan?\",\n",
    "    \"You have a new voicemail. Call now to listen to your messages.\"\n",
    "]\n",
    "\n",
    "# custom threshold for spam\n",
    "threshold = 0.6\n",
    "\n",
    "for email in test_emails:\n",
    "    pred, pred_idx, probs = learn.predict(email)\n",
    "    prob_spam = float(probs[1])\n",
    "    label = 1 if prob_spam >= threshold else 0\n",
    "    print(f\"\\nEmail: {email}\")\n",
    "    print(f\"Predicted: {'SPAM' if label == 1 else 'NOT SPAM'} (probability {prob_spam:.2f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyint_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
